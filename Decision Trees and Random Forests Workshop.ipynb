{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree -- Theory**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest -- Theory**\n",
    "\n",
    "As the name implies, a random forest is built from an **ensemble** of decision trees. While this method improves the accuracy of the classifier/regressor, the results are clearly less interpretable than they are in a single decision tree.\n",
    "\n",
    "So how do we create more than one tree? The naive approach would be to repeat the above algorithm for decision trees multiple times, but this would end up creating highly-correlated trees. Instead, we can **bag** the data: for each tree, choose $n$ samples from the training set (*with* replacement).\n",
    "\n",
    "Now, if any features are strong predictors across the data set, they will likely be chosen earlier in the learning process for multiple trees, which may cause the trees to become correlated. To remedy this, at each step (node) of the learning process for the decision tree, consider only $d$ distinct features, and select the best feature to split the node.\n",
    "\n",
    "To use this model for evaluation, we can take an aggregate result of the decision trees. For a classification prediction, this involves a simple majority vote of the trees' predicted values. For a regression problem, the model takes the average of all individual regression trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will work on implementing the Decision Tree and Random Forest architectures. The first step is importing the packages and methods we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is making the data. We will use two datasets for this project. ___ To make the data easier to work with, we will convert the csv files into pandas dataframes. We will also seperate the target variables (i.e. the y values) into seperate objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DSWRF_SFC_0000</th>\n",
       "      <th>DSWRF_SFC_0001</th>\n",
       "      <th>DSWRF_SFC_0002</th>\n",
       "      <th>DSWRF_SFC_0003</th>\n",
       "      <th>DSWRF_SFC_0004</th>\n",
       "      <th>DSWRF_SFC_0005</th>\n",
       "      <th>DSWRF_SFC_0006</th>\n",
       "      <th>DSWRF_SFC_0007</th>\n",
       "      <th>DSWRF_SFC_0008</th>\n",
       "      <th>DSWRF_SFC_0009</th>\n",
       "      <th>...</th>\n",
       "      <th>VIS_SFC_0019</th>\n",
       "      <th>VIS_SFC_0020</th>\n",
       "      <th>VIS_SFC_0021</th>\n",
       "      <th>VIS_SFC_0022</th>\n",
       "      <th>VIS_SFC_0023</th>\n",
       "      <th>VIS_SFC_0024</th>\n",
       "      <th>time_of_day_cos</th>\n",
       "      <th>time_of_day_sin</th>\n",
       "      <th>time_of_year_cos</th>\n",
       "      <th>time_of_year_sin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>7.750</td>\n",
       "      <td>18.25</td>\n",
       "      <td>...</td>\n",
       "      <td>426.895569</td>\n",
       "      <td>227.899689</td>\n",
       "      <td>228.550201</td>\n",
       "      <td>428.331696</td>\n",
       "      <td>227.286820</td>\n",
       "      <td>224.271637</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977848</td>\n",
       "      <td>0.209315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>106.5</td>\n",
       "      <td>63.875</td>\n",
       "      <td>90.750</td>\n",
       "      <td>17.875</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>7824.965820</td>\n",
       "      <td>4825.635742</td>\n",
       "      <td>2627.959229</td>\n",
       "      <td>2628.863281</td>\n",
       "      <td>4828.833008</td>\n",
       "      <td>9027.083984</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.976011</td>\n",
       "      <td>0.217723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>24226.927730</td>\n",
       "      <td>24223.308590</td>\n",
       "      <td>14824.718750</td>\n",
       "      <td>20222.730470</td>\n",
       "      <td>16624.769530</td>\n",
       "      <td>19425.916020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.975065</td>\n",
       "      <td>0.221922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.50</td>\n",
       "      <td>60.125</td>\n",
       "      <td>50.25</td>\n",
       "      <td>...</td>\n",
       "      <td>5625.299316</td>\n",
       "      <td>8026.288086</td>\n",
       "      <td>20024.955080</td>\n",
       "      <td>6023.587402</td>\n",
       "      <td>24223.126950</td>\n",
       "      <td>24222.828130</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974100</td>\n",
       "      <td>0.226116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.625</td>\n",
       "      <td>105.625</td>\n",
       "      <td>55.375</td>\n",
       "      <td>140.75</td>\n",
       "      <td>100.0</td>\n",
       "      <td>77.25</td>\n",
       "      <td>56.25</td>\n",
       "      <td>80.125</td>\n",
       "      <td>44.50</td>\n",
       "      <td>...</td>\n",
       "      <td>23823.607420</td>\n",
       "      <td>24223.201170</td>\n",
       "      <td>10823.557620</td>\n",
       "      <td>17022.439450</td>\n",
       "      <td>5824.313965</td>\n",
       "      <td>24222.529300</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.973118</td>\n",
       "      <td>0.230306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DSWRF_SFC_0000  DSWRF_SFC_0001  DSWRF_SFC_0002  DSWRF_SFC_0003  \\\n",
       "0             0.0           0.000           0.000           0.000   \n",
       "1           106.5          63.875          90.750          17.875   \n",
       "2             0.0           0.000           0.000           0.000   \n",
       "3             0.0           0.000           0.000           0.000   \n",
       "4             0.0           8.625         105.625          55.375   \n",
       "\n",
       "   DSWRF_SFC_0004  DSWRF_SFC_0005  DSWRF_SFC_0006  DSWRF_SFC_0007  \\\n",
       "0            0.00             0.0            0.00            1.75   \n",
       "1           10.00             0.0            0.00            0.00   \n",
       "2            0.00             0.0            0.00            0.00   \n",
       "3            0.00             0.0            0.00            6.50   \n",
       "4          140.75           100.0           77.25           56.25   \n",
       "\n",
       "   DSWRF_SFC_0008  DSWRF_SFC_0009  ...  VIS_SFC_0019  VIS_SFC_0020  \\\n",
       "0           7.750           18.25  ...    426.895569    227.899689   \n",
       "1           0.000            0.00  ...   7824.965820   4825.635742   \n",
       "2           0.000            0.00  ...  24226.927730  24223.308590   \n",
       "3          60.125           50.25  ...   5625.299316   8026.288086   \n",
       "4          80.125           44.50  ...  23823.607420  24223.201170   \n",
       "\n",
       "   VIS_SFC_0021  VIS_SFC_0022  VIS_SFC_0023  VIS_SFC_0024  time_of_day_cos  \\\n",
       "0    228.550201    428.331696    227.286820    224.271637                0   \n",
       "1   2627.959229   2628.863281   4828.833008   9027.083984                0   \n",
       "2  14824.718750  20222.730470  16624.769530  19425.916020                1   \n",
       "3  20024.955080   6023.587402  24223.126950  24222.828130                0   \n",
       "4  10823.557620  17022.439450   5824.313965  24222.529300               -1   \n",
       "\n",
       "   time_of_day_sin  time_of_year_cos  time_of_year_sin  \n",
       "0                1          0.977848          0.209315  \n",
       "1               -1          0.976011          0.217723  \n",
       "2                0          0.975065          0.221922  \n",
       "3                1          0.974100          0.226116  \n",
       "4                0          0.973118          0.230306  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process CSV files into dataframes\n",
    "cancer_df = pd.read_csv('data/breast_cancer.csv')\n",
    "cancer_df.pop('ID')\n",
    "solar_df = pd.read_csv('data/solar.csv')\n",
    "\n",
    "# Make target objects\n",
    "cancer_y = cancer_df.pop('diagnosis')\n",
    "solar_y = solar_df.pop('SOLARRADIATION_0003')\n",
    "solar_df = solar_df.iloc[:,1:]\n",
    "\n",
    "# Print results\n",
    "cancer_df.head()\n",
    "solar_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another imporant part of data processing is normalizing the data. This usually means putting each data value in the dataframe somewhere between one and zero. Often, this is done by subtracting the observation from the maximum observation and then dividing by the range ($scaled=\\frac{max - unscaled}{max - min}$). We will use a built in sklearn function to do this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(df):\n",
    "    x = df.values\n",
    "    scaler = MinMaxScaler()\n",
    "    x_scaled = scaler.fit_transform(x)\n",
    "    return pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define the method for making a model. You will see the method `makeModel` takes five parameters: `num_features, model, df, y, clf`. `num_features` is the number of input features to consider, as we will only use the n features containing the highest variance. The model `model` is specifies the predefined sklearn model we will use. `df` is the dataframe we will use, `y` is the corresponding target variable, and `clf` is True if we are performing a classfiication task and False if we are performing a regression task.  \n",
    "\n",
    "First, we preprocess the data by normalizing, choosing for features with the highest variance, and splitting into training and testing (we use an 80/20 split). Next, we train the model (using skelarn's `.fit` function) and predict results for the testing data. Lastly, we will calculate metrics to measure the success of the predictions on the testing data. If it's a classification task, we will calculate accuracy, recall, and f1 score. If it is a regression task, we will caclulate mean squared error and the $r^2$ score. If you are not sure how any of these scores are calculated, take a minute to research them. Which of these metrics do you think are most important? Also, notice how many tasks we can simply use the built-in sklearn method for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeModel(num_features, model, df, y, clf):\n",
    "    # Restrict to only features with highest variance + other preprocessing\n",
    "    cols = df.var().sort_values()[(-num_features - 1):].keys()\n",
    "    df = df[df.columns.intersection(cols)]\n",
    "    df = scale(df)\n",
    "    training_x, testing_x, training_y, testing_y = train_test_split(df, y, test_size=0.2)\n",
    "    \n",
    "    # Fit model and predict results\n",
    "    model.fit(training_x, training_y)\n",
    "    pred = model.predict(testing_x)\n",
    "    print(str(model) + \" with \" + str(num_features) + \" features: \")\n",
    "    \n",
    "    if clf:       \n",
    "        # Test for accuracy, recall, and f1 score\n",
    "        accuracy = accuracy_score(testing_y, pred)\n",
    "        recall = recall_score(testing_y, pred, pos_label = 'M') #Double Check? \n",
    "        f1 = f1_score(testing_y, pred, pos_label = 'M')\n",
    "        print (\"\\tAccuracy of \" + str(accuracy))\n",
    "        print (\"\\tRecall of \" + str(recall))\n",
    "        print (\"\\tF1 of \" + str(f1))\n",
    "    else:\n",
    "        # Test for mean squared error and r2 score.\n",
    "        mse = mean_squared_error(testing_y, pred)\n",
    "        r2 = r2_score(testing_y, pred)\n",
    "        print(\"\\tMean Squared Error of \" + str(mse))\n",
    "        print(\"\\tR2 Score of \" + str(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [DecisionTreeClassifier(), LogisticRegression(), RandomForestClassifier()]\n",
    "regressors = [DecisionTreeRegressor(), LinearRegression(), RandomForestRegressor()]\n",
    "for ftrs in range(5, 20, 5):\n",
    "    for clf in classifiers:\n",
    "        makeModel(ftrs, clf, cancer_df, cancer_y, True)\n",
    "    for reg in regressors:\n",
    "        makeModel(ftrs, reg, solar_df, solar_y, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sources**\n",
    "\n",
    "CSCI 6380 with Dr. Fred Maier\n",
    "\n",
    "MIT Open Courseware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}